{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries\n",
        "\n",
        "Here we are \n",
        "- installing libraries, \n",
        "- downloading the crowdhuman dataset zip files, and \n",
        "- unzipping files to the correct directories."
      ],
      "metadata": {
        "id": "dOfoExE40ZKz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzCK3dr17lIa"
      },
      "outputs": [],
      "source": [
        "# Install mmdetection\n",
        "!pip install -U openmim\n",
        "!mim install mmengine\n",
        "!mim install \"mmcv>=2.0.0\"\n",
        "!mim install mmdet\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download zips\n",
        "!wget http://codingai-s3.s3.amazonaws.com/public/crowdhuman.zip\n",
        "!wget http://codingai-s3.s3.amazonaws.com/public/crowdhuman_annotations.zip\n",
        "!wget http://codingai-s3.s3.amazonaws.com/public/crowdhuman_demo_config.py"
      ],
      "metadata": {
        "id": "TM6G4owe8chM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip\n",
        "!mkdir mmdetection/data\n",
        "!unzip crowdhuman.zip -d mmdetection/data\n",
        "!mv mmdetection/data/crowdhuman mmdetection/data/coco\n",
        "!unzip crowdhuman_annotations.zip -d mmdetection/data/coco\n",
        "!mv crowdhuman_demo_config.py mmdetection/."
      ],
      "metadata": {
        "id": "tVb9h4N79q79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View Random Image in Labeled Dataset\n",
        "Run the scripts below to view a random file from our dataset. "
      ],
      "metadata": {
        "id": "oVZj90iH77xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, cv2, glob, random\n",
        "import matplotlib.pyplot as plt\n",
        "def draw_annotations_on_image(file_name, annotations):\n",
        "    # Read the image using OpenCV\n",
        "    image = cv2.imread(file_name)\n",
        "    \n",
        "    # Loop through the annotations and draw the bounding boxes and labels\n",
        "    for annotation in annotations:\n",
        "        bbox = annotation[0][\"bbox\"]\n",
        "        category = annotation[1]\n",
        "        x, y, w, h = map(int, bbox)\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
        "        cv2.putText(image, category, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 3)\n",
        "    \n",
        "    # Save the image with the bounding boxes and labels to a new file\n",
        "    #cv2.imwrite(\"new.jpg\", image)\n",
        "    return image\n",
        "def get_annotations_for_image(file_name, annotations_dict):\n",
        "    # Find the image ID corresponding to the given file name\n",
        "    image_id = None\n",
        "    for image in annotations_dict[\"images\"]:\n",
        "        if image[\"file_name\"] == file_name:\n",
        "            image_id = image[\"id\"]\n",
        "            break\n",
        "    if image_id is None:\n",
        "        raise ValueError(f\"No image found with file name '{file_name}'\")\n",
        "    \n",
        "    # Find all annotations related to the image\n",
        "    annotations = []\n",
        "    for annotation in annotations_dict[\"annotations\"]:\n",
        "        if annotation[\"image_id\"] == image_id:\n",
        "            category_id = annotation[\"category_id\"]\n",
        "            # Find the relevant category\n",
        "            category = None\n",
        "            for cat in annotations_dict[\"categories\"]:\n",
        "                if cat[\"id\"] == category_id:\n",
        "                    category = cat[\"name\"]\n",
        "                    break\n",
        "            if category is None:\n",
        "                raise ValueError(f\"No category found with ID '{category_id}'\")\n",
        "            # Add the annotation and category as a tuple to the list\n",
        "            annotations.append((annotation, category))\n",
        "    \n",
        "    return annotations\n",
        "def get_random_file(mydir):\n",
        "    files = glob.glob(os.path.join(mydir,'*'))\n",
        "    i = random.randint(0,len(files)-1)\n",
        "    return files[i]\n",
        "def view_random_labeled_image(img_dir,annotation_file):\n",
        "    filename = get_random_file(img_dir)\n",
        "    subname = os.path.split(filename)[1]\n",
        "    annotations_dict = json.load(open(annotation_file,'r'))\n",
        "    annotations = get_annotations_for_image(subname,annotations_dict)\n",
        "\n",
        "    image=draw_annotations_on_image(filename, annotations)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.clf()\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('on')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "35w70KYv7c1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each time you run it the cell, you should get a different image. Note: If you are getting some error, your directories may be places in the wrong place."
      ],
      "metadata": {
        "id": "L9Nd1O-E9fUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTATION_FILE = 'mmdetection/data/coco/annotations/instances_train2017.json'\n",
        "IMAGES_DIR = 'mmdetection/data/coco/train2017'\n",
        "\n",
        "view_random_labeled_image(IMAGES_DIR,ANNOTATION_FILE)"
      ],
      "metadata": {
        "id": "7y4z_ZA68bH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Your Object Detector\n",
        "We have the dataset. We have a configuration. Let's train your custom object detector."
      ],
      "metadata": {
        "id": "3GJuMx6ZE6CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/mmdetection"
      ],
      "metadata": {
        "id": "iw4mLTCAF-7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py crowdhuman_demo_config.py"
      ],
      "metadata": {
        "id": "Sqzrj_GK8pS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Inference with Your Model"
      ],
      "metadata": {
        "id": "RyaXhDwVLCka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and use below if you did not train your own model\n",
        "\n",
        "# !wget http://codingai-s3.s3.amazonaws.com/public/crowdhuman_epoch_1.pth\n",
        "# !wget http://codingai-s3.s3.amazonaws.com/public/crowdhuman_demo_config.py\n",
        "# !mv crowdhuman_epoch_1.pth /content/mmdetection/.\n",
        "# !mv crowdhuman_demo_config.py /content/mmdetection/."
      ],
      "metadata": {
        "id": "XCHgtAt9UsOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mmcv\n",
        "from mmcv.transforms import Compose\n",
        "from mmengine.utils import track_iter_progress\n",
        "from mmdet.registry import VISUALIZERS\n",
        "from mmdet.apis import init_detector, inference_detector\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "CONFIG= '/content/mmdetection/crowdhuman_demo_config.py'\n",
        "CHECKPOINT = '/content/mmdetection/work_dirs/faster-rcnn_r50-caffe_fpn_ms-1x_coco-person/epoch_1.pth'\n",
        "#CHECKPOINT = '/content/mmdetection/crowdhuman_epoch_1.pth' # Use this if you did not train your own model\n",
        "\n",
        "# Build the model from a config file and a checkpoint file\n",
        "model = init_detector(CONFIG, CHECKPOINT, device='cuda:0')\n",
        "model.cfg.test_dataloader.dataset.pipeline[0].type = 'LoadImageFromNDArray'\n",
        "test_pipeline = Compose(model.cfg.test_dataloader.dataset.pipeline)\n",
        "\n",
        "# Visualizer is used to show results of detector\n",
        "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
        "visualizer.dataset_meta = model.dataset_meta"
      ],
      "metadata": {
        "id": "prbGmvlyFcxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://codingai-s3.s3.amazonaws.com/public/sample2.png\n",
        "IMAGE_PATH = 'sample2.png'\n",
        "\n",
        "image = mmcv.imread(IMAGE_PATH)\n",
        "image = mmcv.imconvert(image, 'bgr', 'rgb')\n",
        "plt.clf()\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "plt.axis('on')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dQpf-jaaM5TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the results\n",
        "\n",
        "result = inference_detector(model, image, test_pipeline=test_pipeline)\n",
        "\n",
        "visualizer.add_datasample(\n",
        "        'result',\n",
        "        image,\n",
        "        data_sample=result,\n",
        "        draw_gt=False)\n",
        "vis_image = visualizer.get_image()\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(vis_image)\n",
        "plt.axis('on')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mpC-GRFaMxmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "instances = result.pred_instances.numpy().cpu()\n",
        "print(instances)\n",
        "print(\"\")\n",
        "print(\"Congrats! You've just run an image through your newly trained object detector.\\n\")\n",
        "print(\"The details of the detections are found above\\n\")"
      ],
      "metadata": {
        "id": "DFS-mYUdXw0h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}